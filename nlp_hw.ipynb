{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:09:35.142013262Z",
     "start_time": "2023-10-06T13:09:35.099778546Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from datasets import Dataset\n",
    "from torch import nn, optim\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:09:40.951826723Z",
     "start_time": "2023-10-06T13:09:40.931936283Z"
    }
   },
   "id": "e98eef559405366f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:07:56.051628011Z",
     "start_time": "2023-10-06T13:07:56.045939031Z"
    }
   },
   "id": "d535fa2f80a334cd"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/IMDB_Dataset.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:07:56.950375798Z",
     "start_time": "2023-10-06T13:07:56.049667695Z"
    }
   },
   "id": "3266b7e875f0e52d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              review sentiment  sentiment_int\n0  One of the other reviewers has mentioned that ...  positive              0\n1  A wonderful little production. <br /><br />The...  positive              0\n2  I thought this was a wonderful way to spend ti...  positive              0\n3  Basically there's a family where a little boy ...  negative              1\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive              0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>sentiment_int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_int = {'positive' : 0, 'negative': 1}\n",
    "df['sentiment_int'] = df.sentiment.map(sentiment_int)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:07:57.005175260Z",
     "start_time": "2023-10-06T13:07:56.959092272Z"
    }
   },
   "id": "416c383d886db089"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:07:57.059947856Z",
     "start_time": "2023-10-06T13:07:57.007364433Z"
    }
   },
   "id": "2fef4776b65e513c"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "((45000, 3), (2500, 3), (2500, 3))"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T12:48:03.737708903Z",
     "start_time": "2023-10-06T12:48:03.673673935Z"
    }
   },
   "id": "452eb40a9e85f7a8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class ReviewsDataset:\n",
    "\n",
    "    def __init__(self, reviews, targets, tokenizer, max_len=None):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        target = self.targets[item]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:07:57.060412965Z",
     "start_time": "2023-10-06T13:07:57.034065007Z"
    }
   },
   "id": "8c98ad437302c73b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, batch_size, max_len=None):\n",
    "    ds = ReviewsDataset(\n",
    "        reviews=df.review.to_numpy(),\n",
    "        targets=df.sentiment_int.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:07:57.101827201Z",
     "start_time": "2023-10-06T13:07:57.044538814Z"
    }
   },
   "id": "e50368fda786a982"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:07:57.467086302Z",
     "start_time": "2023-10-06T13:07:57.054291972Z"
    }
   },
   "id": "d1fed44f4fba5471"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, BATCH_SIZE, 160)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, BATCH_SIZE, 160)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, BATCH_SIZE, 160)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:10:12.795754971Z",
     "start_time": "2023-10-06T13:10:12.789618848Z"
    }
   },
   "id": "4c3dbc0fa03b59d7"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes=2):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:10:13.672406613Z",
     "start_time": "2023-10-06T13:10:13.664673073Z"
    }
   },
   "id": "bec44a8af6872d70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = SentimentClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-06T13:10:15.436276972Z"
    }
   },
   "id": "263f85d8979b54e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.NLLLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-06T13:15:50.041541970Z"
    }
   },
   "id": "cf6773f178de66d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f3c2dec6d13797a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "      model,\n",
    "      data_loader,\n",
    "      loss_fn,\n",
    "      optimizer,\n",
    "      device,\n",
    "      scheduler,\n",
    "      n_examples\n",
    "    ):\n",
    "    \n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in data_loader:   \n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "        outputs = model(\n",
    "          input_ids=input_ids,\n",
    "          attention_mask=attention_mask\n",
    "        )\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:08:04.356516707Z",
     "start_time": "2023-10-06T13:08:04.333405926Z"
    }
   },
   "id": "e338b819abc4a5fe"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:08:37.975311081Z",
     "start_time": "2023-10-06T13:08:37.959220287Z"
    }
   },
   "id": "b0bed81faadffe93"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/IPython/core/magics/\u001B[0m\u001B[1;33me\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[1;33mxecution.py\u001B[0m:\u001B[94m1319\u001B[0m in \u001B[92mtime\u001B[0m                                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1316 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1317 \u001B[0m\u001B[2m│   │   │   \u001B[0mst = clock2()                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1318 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mtry\u001B[0m:                                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1319 \u001B[2m│   │   │   │   \u001B[0mexec(code, glob, local_ns)                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1320 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mout=\u001B[94mNone\u001B[0m                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1321 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[2m# multi-line %%time case\u001B[0m                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1322 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mif\u001B[0m expr_val \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m:                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92m<module>\u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92mtrain_epoch\u001B[0m                                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m11 \u001B[0m\u001B[2m│   \u001B[0mmodel = model.train()                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m12 \u001B[0m\u001B[2m│   \u001B[0mlosses = []                                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m13 \u001B[0m\u001B[2m│   \u001B[0mcorrect_predictions = \u001B[94m0\u001B[0m                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m14 \u001B[2m│   \u001B[0m\u001B[94mfor\u001B[0m d \u001B[95min\u001B[0m data_loader:                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m15 \u001B[0m\u001B[2m│   │   \u001B[0minput_ids = d[\u001B[33m\"\u001B[0m\u001B[33minput_ids\u001B[0m\u001B[33m\"\u001B[0m].to(device)                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m16 \u001B[0m\u001B[2m│   │   \u001B[0mattention_mask = d[\u001B[33m\"\u001B[0m\u001B[33mattention_mask\u001B[0m\u001B[33m\"\u001B[0m].to(device)                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m17 \u001B[0m\u001B[2m│   │   \u001B[0mtargets = d[\u001B[33m\"\u001B[0m\u001B[33mtargets\u001B[0m\u001B[33m\"\u001B[0m].to(device)                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/\u001B[0m\u001B[1;33mdata\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[1;33mloader.py\u001B[0m:\u001B[94m633\u001B[0m in \u001B[92m__next__\u001B[0m                                                                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 630 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96mself\u001B[0m._sampler_iter \u001B[95mis\u001B[0m \u001B[94mNone\u001B[0m:                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 631 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[2m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[0m                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 632 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[96mself\u001B[0m._reset()  \u001B[2m# type: ignore[call-arg]\u001B[0m                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 633 \u001B[2m│   │   │   \u001B[0mdata = \u001B[96mself\u001B[0m._next_data()                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 634 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m._num_yielded += \u001B[94m1\u001B[0m                                                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 635 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96mself\u001B[0m._dataset_kind == _DatasetKind.Iterable \u001B[95mand\u001B[0m \\                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 636 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[96mself\u001B[0m._IterableDataset_len_called \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m \u001B[95mand\u001B[0m \\                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/\u001B[0m\u001B[1;33mdata\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[1;33mloader.py\u001B[0m:\u001B[94m1345\u001B[0m in \u001B[92m_next_data\u001B[0m                                                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1342 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[96mself\u001B[0m._task_info[idx] += (data,)                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1343 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1344 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mdel\u001B[0m \u001B[96mself\u001B[0m._task_info[idx]                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1345 \u001B[2m│   │   │   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m._process_data(data)                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1346 \u001B[0m\u001B[2m│   \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1347 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92m_try_put_index\u001B[0m(\u001B[96mself\u001B[0m):                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1348 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94massert\u001B[0m \u001B[96mself\u001B[0m._tasks_outstanding < \u001B[96mself\u001B[0m._prefetch_factor * \u001B[96mself\u001B[0m._num_workers        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/\u001B[0m\u001B[1;33mdata\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[1;33mloader.py\u001B[0m:\u001B[94m1371\u001B[0m in \u001B[92m_process_data\u001B[0m                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1368 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[96mself\u001B[0m._rcvd_idx += \u001B[94m1\u001B[0m                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1369 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[96mself\u001B[0m._try_put_index()                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1370 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96misinstance\u001B[0m(data, ExceptionWrapper):                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1371 \u001B[2m│   │   │   \u001B[0mdata.reraise()                                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1372 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m data                                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1373 \u001B[0m\u001B[2m│   \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1374 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92m_mark_worker_as_unavailable\u001B[0m(\u001B[96mself\u001B[0m, worker_id, shutdown=\u001B[94mFalse\u001B[0m):                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/\u001B[0m\u001B[1;33m_utils.py\u001B[0m:\u001B[94m644\u001B[0m   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92mreraise\u001B[0m                                                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m641 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# If the exception takes multiple arguments, don't try to\u001B[0m                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m642 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# instantiate since we don't know how to\u001B[0m                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m643 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mraise\u001B[0m \u001B[96mRuntimeError\u001B[0m(msg) \u001B[94mfrom\u001B[0m \u001B[96mNone\u001B[0m                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m644 \u001B[2m│   │   \u001B[0m\u001B[94mraise\u001B[0m exception                                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m645 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m646 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m647 \u001B[0m\u001B[94mdef\u001B[0m \u001B[92m_get_available_device_type\u001B[0m():                                                          \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mRuntimeError: \u001B[0mCaught RuntimeError in DataLoader worker process \u001B[1;36m0\u001B[0m.\nOriginal Traceback \u001B[1m(\u001B[0mmost recent call last\u001B[1m)\u001B[0m:\n  File \n\u001B[32m\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\"\u001B[0m, \nline \u001B[1;36m308\u001B[0m, in _worker_loop\n    data = \u001B[1;35mfetcher.fetch\u001B[0m\u001B[1m(\u001B[0mindex\u001B[1m)\u001B[0m\n  File \n\u001B[32m\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\"\u001B[0m, line\n\u001B[1;36m54\u001B[0m, in fetch\n    return \u001B[1;35mself.collate_fn\u001B[0m\u001B[1m(\u001B[0mdata\u001B[1m)\u001B[0m\n  File \n\u001B[32m\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"\u001B[0m, \nline \u001B[1;36m265\u001B[0m, in default_collate\n    return \u001B[1;35mcollate\u001B[0m\u001B[1m(\u001B[0mbatch, \u001B[33mcollate_fn_map\u001B[0m=\u001B[35mdefault_collate_fn_map\u001B[0m\u001B[1m)\u001B[0m\n  File \n\u001B[32m\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"\u001B[0m, \nline \u001B[1;36m127\u001B[0m, in collate\n    return \u001B[1;35melem_type\u001B[0m\u001B[1m(\u001B[0m\u001B[1m{\u001B[0mkey: \u001B[1;35mcollate\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0md\u001B[1m[\u001B[0mkey\u001B[1m]\u001B[0m for d in batch\u001B[1m]\u001B[0m, \u001B[33mcollate_fn_map\u001B[0m=\u001B[35mcollate_fn_map\u001B[0m\u001B[1m)\u001B[0m for key in elem\u001B[1m}\u001B[0m\u001B[1m)\u001B[0m\n  File \n\u001B[32m\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"\u001B[0m, \nline \u001B[1;36m127\u001B[0m, in \u001B[1m<\u001B[0m\u001B[1;95mdictcomp\u001B[0m\u001B[1m>\u001B[0m\n    return \u001B[1;35melem_type\u001B[0m\u001B[1m(\u001B[0m\u001B[1m{\u001B[0mkey: \u001B[1;35mcollate\u001B[0m\u001B[1m(\u001B[0m\u001B[1m[\u001B[0md\u001B[1m[\u001B[0mkey\u001B[1m]\u001B[0m for d in batch\u001B[1m]\u001B[0m, \u001B[33mcollate_fn_map\u001B[0m=\u001B[35mcollate_fn_map\u001B[0m\u001B[1m)\u001B[0m for key in elem\u001B[1m}\u001B[0m\u001B[1m)\u001B[0m\n  File \n\u001B[32m\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"\u001B[0m, \nline \u001B[1;36m119\u001B[0m, in collate\n    return collate_fn_map\u001B[1m[\u001B[0melem_type\u001B[1m]\u001B[0m\u001B[1m(\u001B[0mbatch, \u001B[33mcollate_fn_map\u001B[0m=\u001B[35mcollate_fn_map\u001B[0m\u001B[1m)\u001B[0m\n  File \n\u001B[32m\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"\u001B[0m, \nline \u001B[1;36m162\u001B[0m, in collate_tensor_fn\n    return \u001B[1;35mtorch.stack\u001B[0m\u001B[1m(\u001B[0mbatch, \u001B[1;36m0\u001B[0m, \u001B[33mout\u001B[0m=\u001B[35mout\u001B[0m\u001B[1m)\u001B[0m\nRuntimeError: stack expects each tensor to be equal size, but got \u001B[1m[\u001B[0m\u001B[1;36m193\u001B[0m\u001B[1m]\u001B[0m at entry \u001B[1;36m0\u001B[0m and \u001B[1m[\u001B[0m\u001B[1;36m348\u001B[0m\u001B[1m]\u001B[0m at entry \u001B[1;36m1\u001B[0m\n\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/IPython/core/magics/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">e</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">xecution.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1319</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">time</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1316 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1317 │   │   │   </span>st = clock2()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1318 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1319 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>exec(code, glob, local_ns)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1320 │   │   │   │   </span>out=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1321 │   │   │   │   # multi-line %%time case</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1322 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> expr_val <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_epoch</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 │   </span>model = model.train()                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 │   </span>losses = []                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 │   </span>correct_predictions = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>14 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> d <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> data_loader:                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 │   │   </span>input_ids = d[<span style=\"color: #808000; text-decoration-color: #808000\">\"input_ids\"</span>].to(device)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 │   │   </span>attention_mask = d[<span style=\"color: #808000; text-decoration-color: #808000\">\"attention_mask\"</span>].to(device)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 │   │   </span>targets = d[<span style=\"color: #808000; text-decoration-color: #808000\">\"targets\"</span>].to(device)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">loader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">633</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__next__</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 630 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sampler_iter <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 631 │   │   │   │   # TODO(https://github.com/pytorch/pytorch/issues/76750)</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 632 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reset()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[call-arg]</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 633 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_data()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 634 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_yielded += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 635 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 636 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._IterableDataset_len_called <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">loader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1345</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1342 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._task_info[idx] += (data,)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1343 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1344 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">del</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._task_info[idx]                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1345 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._process_data(data)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1346 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1347 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_try_put_index</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1348 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._tasks_outstanding &lt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._prefetch_factor * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_workers        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">loader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1371</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_process_data</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1368 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._rcvd_idx += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1369 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._try_put_index()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1370 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(data, ExceptionWrapper):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1371 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data.reraise()                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1372 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1373 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1374 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_mark_worker_as_unavailable</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, worker_id, shutdown=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">644</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reraise</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">641 │   │   │   # If the exception takes multiple arguments, don't try to</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">642 │   │   │   # instantiate since we don't know how to</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">643 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(msg) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">None</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>644 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> exception                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">645 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">646 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">647 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_available_device_type</span>():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Caught RuntimeError in DataLoader worker process <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.\nOriginal Traceback <span style=\"font-weight: bold\">(</span>most recent call last<span style=\"font-weight: bold\">)</span>:\n  File \n<span style=\"color: #008000; text-decoration-color: #008000\">\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\"</span>, \nline <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">308</span>, in _worker_loop\n    data = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">fetcher.fetch</span><span style=\"font-weight: bold\">(</span>index<span style=\"font-weight: bold\">)</span>\n  File \n<span style=\"color: #008000; text-decoration-color: #008000\">\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\"</span>, line\n<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54</span>, in fetch\n    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.collate_fn</span><span style=\"font-weight: bold\">(</span>data<span style=\"font-weight: bold\">)</span>\n  File \n<span style=\"color: #008000; text-decoration-color: #008000\">\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"</span>, \nline <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">265</span>, in default_collate\n    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">collate</span><span style=\"font-weight: bold\">(</span>batch, <span style=\"color: #808000; text-decoration-color: #808000\">collate_fn_map</span>=<span style=\"color: #800080; text-decoration-color: #800080\">default_collate_fn_map</span><span style=\"font-weight: bold\">)</span>\n  File \n<span style=\"color: #008000; text-decoration-color: #008000\">\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"</span>, \nline <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>, in collate\n    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">elem_type</span><span style=\"font-weight: bold\">({</span>key: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">collate</span><span style=\"font-weight: bold\">([</span>d<span style=\"font-weight: bold\">[</span>key<span style=\"font-weight: bold\">]</span> for d in batch<span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">collate_fn_map</span>=<span style=\"color: #800080; text-decoration-color: #800080\">collate_fn_map</span><span style=\"font-weight: bold\">)</span> for key in elem<span style=\"font-weight: bold\">})</span>\n  File \n<span style=\"color: #008000; text-decoration-color: #008000\">\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"</span>, \nline <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>, in <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">dictcomp</span><span style=\"font-weight: bold\">&gt;</span>\n    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">elem_type</span><span style=\"font-weight: bold\">({</span>key: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">collate</span><span style=\"font-weight: bold\">([</span>d<span style=\"font-weight: bold\">[</span>key<span style=\"font-weight: bold\">]</span> for d in batch<span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">collate_fn_map</span>=<span style=\"color: #800080; text-decoration-color: #800080\">collate_fn_map</span><span style=\"font-weight: bold\">)</span> for key in elem<span style=\"font-weight: bold\">})</span>\n  File \n<span style=\"color: #008000; text-decoration-color: #008000\">\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"</span>, \nline <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119</span>, in collate\n    return collate_fn_map<span style=\"font-weight: bold\">[</span>elem_type<span style=\"font-weight: bold\">](</span>batch, <span style=\"color: #808000; text-decoration-color: #808000\">collate_fn_map</span>=<span style=\"color: #800080; text-decoration-color: #800080\">collate_fn_map</span><span style=\"font-weight: bold\">)</span>\n  File \n<span style=\"color: #008000; text-decoration-color: #008000\">\"/home/ivan/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"</span>, \nline <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">162</span>, in collate_tensor_fn\n    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.stack</span><span style=\"font-weight: bold\">(</span>batch, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out</span>=<span style=\"color: #800080; text-decoration-color: #800080\">out</span><span style=\"font-weight: bold\">)</span>\nRuntimeError: stack expects each tensor to be equal size, but got <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span><span style=\"font-weight: bold\">]</span> at entry <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> and <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">348</span><span style=\"font-weight: bold\">]</span> at entry <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(df_train)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_data_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(df_val)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:09:48.784645648Z",
     "start_time": "2023-10-06T13:09:46.857023653Z"
    }
   },
   "id": "ceea4a4028231c65"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
